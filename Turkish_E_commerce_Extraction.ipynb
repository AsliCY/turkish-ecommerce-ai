{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Turkish E-commerce Product Information Extraction with Fine-Tuned LLaMA\n"
      ],
      "metadata": {
        "id": "8RhccOnt0Rhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéØ Project Overview\n",
        "This project fine-tunes LLaMA 3.2 3B model using Unsloth to extract structured product information from Turkish e-commerce HTML pages. The model converts unstructured HTML content into clean JSON format, making it ideal for web scraping, price monitoring, and data analysis applications.\n",
        "\n",
        "## ‚ú® Key Features\n",
        "\n",
        "- üáπüá∑ Turkish Language Specialized: Optimized for Turkish e-commerce websites\n",
        "- üöÄ High Performance: Fine-tuned with 500+ synthetic examples\n",
        "- üìä JSON Output: Clean, structured data extraction\n",
        "- ‚ö° Local Deployment: Works with Ollama for privacy\n",
        "- üéõÔ∏è Customizable: Easy to extend for new product categories\n",
        "\n",
        "## üèóÔ∏è Architecture\n",
        "\n",
        "HTML Input ‚Üí Fine-Tuned LLaMA 3.2 3B ‚Üí Structured JSON Output\n",
        "### Model Details:\n",
        "\n",
        "* Base Model: unsloth/Llama-3.2-3B-Instruct-bnb-4bit\n",
        "* Fine-tuning: LoRA (Low-Rank Adaptation)\n",
        "* Quantization: Q4_K_M for optimal size/performance balance\n",
        "* Deployment: Ollama GGUF format\n",
        "\n",
        "## üìã Table of Contents\n",
        "\n",
        "1. Setup & Installation\n",
        "2. Dataset Generation\n",
        "3. Model Training\n",
        "4. Testing & Validation\n",
        "5. GGUF Conversion\n",
        "6. Ollama Deployment\n",
        "7. Usage Examples\n",
        "8. Performance Metrics\n",
        "\n",
        "\n",
        "## üöÄ Setup & Installation\n",
        "### Prerequisites\n",
        "\n",
        "* Google Colab with GPU (T4/V100/A100)\n",
        "* Python 3.8+\n",
        "* CUDA compatible GPU (for local training)\n",
        "\n"
      ],
      "metadata": {
        "id": "yP8XdWw70WxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üöÄ TURKISH E-COMMERCE AI MODEL SETUP\n",
        "# Fine-tuning LLaMA 3.2 3B for Turkish e-commerce data extraction\n",
        "# ============================================================================\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üîç System Information\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Python Version: {sys.version}\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected! Please enable GPU in Runtime settings\")\n",
        "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
      ],
      "metadata": {
        "id": "jeIDrq-h1gkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üì¶ INSTALL REQUIRED PACKAGES\n",
        "# Installing Unsloth and dependencies for efficient fine-tuning\n",
        "# ============================================================================\n",
        "\n",
        "print(\"üîß Installing Unsloth for efficient fine-tuning...\")\n",
        "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "\n",
        "print(\"üìö Installing additional dependencies...\")\n",
        "!pip install -q datasets transformers accelerate bitsandbytes trl\n",
        "\n",
        "print(\"‚úÖ Installation completed!\")\n",
        "print(\"‚ö†Ô∏è  IMPORTANT: Please restart runtime now!\")\n",
        "print(\"   Runtime ‚Üí Restart runtime\")"
      ],
      "metadata": {
        "id": "M5ddZcYr1mp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üìä TURKISH E-COMMERCE DATASET GENERATION\n",
        "# Creating diverse synthetic examples for training\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "import random\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "def generate_turkish_ecommerce_dataset(size: int = 500) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Generate synthetic Turkish e-commerce dataset.\n",
        "\n",
        "    Args:\n",
        "        size (int): Number of examples to generate\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: Generated dataset with input/output pairs\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"üìä Generating {size} Turkish e-commerce examples...\")\n",
        "\n",
        "    # Product categories with realistic Turkish products\n",
        "    products = {\n",
        "        \"Telefon\": [\n",
        "            \"iPhone 15 Pro Max\", \"Samsung Galaxy S24 Ultra\", \"Xiaomi 14 Pro\",\n",
        "            \"Google Pixel 8 Pro\", \"OnePlus 12\", \"Huawei P60 Pro\"\n",
        "        ],\n",
        "        \"Laptop\": [\n",
        "            \"MacBook Air M3\", \"Dell XPS 13\", \"HP Envy 15\", \"Asus ROG Strix\",\n",
        "            \"MSI Gaming GF63\", \"Lenovo ThinkPad X1\", \"Surface Laptop 5\"\n",
        "        ],\n",
        "        \"Kulaklƒ±k\": [\n",
        "            \"AirPods Pro 2\", \"Sony WH-1000XM5\", \"Bose QuietComfort 45\",\n",
        "            \"Sennheiser HD 660S\", \"JBL Tour One M2\", \"Marshall Major IV\"\n",
        "        ],\n",
        "        \"Televizyon\": [\n",
        "            \"Samsung QLED 4K\", \"LG OLED C3\", \"Sony Bravia XR\",\n",
        "            \"TCL 4K Android TV\", \"Philips Ambilight\"\n",
        "        ],\n",
        "        \"Ayakkabƒ±\": [\n",
        "            \"Nike Air Max 270\", \"Adidas Ultraboost 22\", \"Puma RS-X\",\n",
        "            \"New Balance 990v6\", \"Converse Chuck Taylor\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Turkish e-commerce seller names\n",
        "    sellers = [\n",
        "        \"ResmiMaƒüaza\", \"TechWorld\", \"Elektronik D√ºnyasƒ±\",\n",
        "        \"Hƒ±zlƒ± Teknoloji\", \"Digital Plaza\", \"Mega Store\"\n",
        "    ]\n",
        "\n",
        "    # Category-specific features\n",
        "    features_by_category = {\n",
        "        \"Telefon\": [\n",
        "            \"128GB Depolama\", \"256GB Depolama\", \"512GB Depolama\",\n",
        "            \"12GB RAM\", \"8GB RAM\", \"48MP Kamera\", \"5G Desteƒüi\",\n",
        "            \"Wireless Charging\", \"Su Ge√ßirmez\", \"Face ID\"\n",
        "        ],\n",
        "        \"Laptop\": [\n",
        "            \"Intel i7 ƒ∞≈ülemci\", \"AMD Ryzen 7\", \"16GB RAM\", \"512GB SSD\",\n",
        "            \"NVIDIA RTX 4060\", \"15.6 ƒ∞n√ß Ekran\", \"Backlit Keyboard\"\n",
        "        ],\n",
        "        \"Kulaklƒ±k\": [\n",
        "            \"Aktif G√ºr√ºlt√º Engelleme\", \"Wireless\", \"30 Saat Pil √ñmr√º\",\n",
        "            \"Hi-Res Audio\", \"Su Ge√ßirmez\", \"Voice Assistant\"\n",
        "        ],\n",
        "        \"Televizyon\": [\n",
        "            \"4K Ultra HD\", \"Smart TV\", \"55 ƒ∞n√ß\", \"HDR10+\",\n",
        "            \"Dolby Vision\", \"Voice Control\"\n",
        "        ],\n",
        "        \"Ayakkabƒ±\": [\n",
        "            \"Air Cushioning\", \"Su Ge√ßirmez\", \"Nefes Alabilen\",\n",
        "            \"Ortopedik Destek\", \"Anti-Slip Taban\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Price ranges by category (in Turkish Lira)\n",
        "    price_ranges = {\n",
        "        \"Telefon\": (15000, 80000),\n",
        "        \"Laptop\": (20000, 100000),\n",
        "        \"Kulaklƒ±k\": (500, 15000),\n",
        "        \"Televizyon\": (8000, 50000),\n",
        "        \"Ayakkabƒ±\": (300, 3000)\n",
        "    }\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for i in range(size):\n",
        "        # Select random category and product\n",
        "        category = random.choice(list(products.keys()))\n",
        "        product = random.choice(products[category])\n",
        "        brand = product.split()[0]  # Extract brand from product name\n",
        "        seller = random.choice(sellers)\n",
        "\n",
        "        # Generate realistic pricing\n",
        "        min_price, max_price = price_ranges[category]\n",
        "        price = random.randint(min_price, max_price)\n",
        "        original_price = price + random.randint(int(price * 0.1), int(price * 0.3))\n",
        "        discount = round(((original_price - price) / original_price) * 100)\n",
        "\n",
        "        # Generate ratings and reviews\n",
        "        rating = round(random.uniform(3.5, 5.0), 1)\n",
        "        review_count = random.randint(10, 5000)\n",
        "\n",
        "        # Select random features\n",
        "        available_features = features_by_category[category]\n",
        "        num_features = random.randint(3, min(6, len(available_features)))\n",
        "        selected_features = random.sample(available_features, num_features)\n",
        "\n",
        "        # Generate HTML template\n",
        "        html_template = f\"\"\"<div class=\"urun-detayi\">\n",
        "    <h1 class=\"baslik\">{product}</h1>\n",
        "    <div class=\"fiyat-bolumu\">\n",
        "        <span class=\"aktuel-fiyat\">{price:,} TL</span>\n",
        "        <span class=\"eski-fiyat\">{original_price:,} TL</span>\n",
        "        <span class=\"indirim-orani\">%{discount} ƒ∞ndirim</span>\n",
        "    </div>\n",
        "    <div class=\"urun-bilgileri\">\n",
        "        <div class=\"marka\">Marka: <strong>{brand}</strong></div>\n",
        "        <div class=\"kategori\">Kategori: {category}</div>\n",
        "        <div class=\"satici\">Satƒ±cƒ±: {seller}</div>\n",
        "    </div>\n",
        "    <div class=\"degerlendirme\">\n",
        "        <span class=\"puan\">{rating}</span>\n",
        "        <span class=\"yorum-sayisi\">({review_count:,} deƒüerlendirme)</span>\n",
        "    </div>\n",
        "    <div class=\"ozellikler\">\n",
        "        <h3>√úr√ºn √ñzellikleri:</h3>\n",
        "        <ul>\n",
        "{\"\".join([f'            <li>{feature}</li>' for feature in selected_features])}\n",
        "        </ul>\n",
        "    </div>\n",
        "    <div class=\"kargo-bilgi\">üöö √úcretsiz Kargo</div>\n",
        "    <div class=\"stok-durumu\">‚úÖ Stokta mevcut</div>\n",
        "</div>\"\"\"\n",
        "\n",
        "        # Generate target JSON output\n",
        "        output = {\n",
        "            \"name\": product,\n",
        "            \"price\": f\"{price:,} TL\",\n",
        "            \"original_price\": f\"{original_price:,} TL\",\n",
        "            \"discount\": f\"%{discount} ƒ∞ndirim\",\n",
        "            \"brand\": brand,\n",
        "            \"category\": category,\n",
        "            \"seller\": seller,\n",
        "            \"rating\": str(rating),\n",
        "            \"review_count\": f\"{review_count:,}\",\n",
        "            \"features\": selected_features,\n",
        "            \"shipping\": \"√úcretsiz Kargo\",\n",
        "            \"availability\": \"Stokta mevcut\"\n",
        "        }\n",
        "\n",
        "        dataset.append({\n",
        "            \"input\": f\"A≈üaƒüƒ±daki T√ºrk√ße e-ticaret √ºr√ºn sayfasƒ±ndan bilgileri √ßƒ±kar:\\n\\n{html_template}\",\n",
        "            \"output\": output\n",
        "        })\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"   ‚úÖ Generated {i + 1}/{size} examples\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Generate dataset\n",
        "dataset = generate_turkish_ecommerce_dataset(500)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready with {len(dataset)} examples!\")\n",
        "\n",
        "# Save dataset\n",
        "with open('turkish_ecommerce_dataset.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nüìù Sample data preview:\")\n",
        "print(\"Input (first 200 chars):\")\n",
        "print(dataset[0][\"input\"][:200] + \"...\")\n",
        "print(\"\\nOutput:\")\n",
        "print(json.dumps(dataset[0][\"output\"], ensure_ascii=False, indent=2))"
      ],
      "metadata": {
        "id": "dS-C59JD1oy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ü§ñ MODEL LOADING & LORA CONFIGURATION\n",
        "# Setting up LLaMA 3.2 3B with efficient fine-tuning\n",
        "# ============================================================================\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\n",
        "MAX_SEQ_LENGTH = 4096\n",
        "\n",
        "print(f\"üîÑ Loading model: {MODEL_NAME}\")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=MODEL_NAME,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Base model loaded successfully!\")\n",
        "\n",
        "# Configure LoRA (Low-Rank Adaptation)\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=64,  # LoRA rank - Higher for better Turkish performance\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=128,  # 2x rank\n",
        "    lora_dropout=0.1,  # Prevent overfitting\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=42,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ LoRA adapters configured!\")\n",
        "print(f\"üìä Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ],
      "metadata": {
        "id": "Fwf7sufA1qZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üìä DATA PREPROCESSING & FORMATTING\n",
        "# Preparing dataset for fine-tuning\n",
        "# ============================================================================\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "def format_prompt_turkish(example):\n",
        "    \"\"\"Format training examples with Turkish e-commerce prompt template.\"\"\"\n",
        "    return f\"\"\"### G√∂rev:\n",
        "{example['input']}\n",
        "\n",
        "### √áƒ±ktƒ±:\n",
        "{json.dumps(example['output'], ensure_ascii=False)}<|endoftext|>\"\"\"\n",
        "\n",
        "# Load and format dataset\n",
        "with open('turkish_ecommerce_dataset.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Format all examples\n",
        "formatted_data = [format_prompt_turkish(item) for item in data]\n",
        "train_dataset = Dataset.from_dict({\"text\": formatted_data})\n",
        "\n",
        "print(f\"‚úÖ Formatted {len(train_dataset)} training examples\")\n",
        "print(\"\\nüìù Sample formatted prompt:\")\n",
        "print(\"=\" * 80)\n",
        "print(train_dataset[0]['text'][:500] + \"...\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "nI1Jbd321sxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üöÄ FINE-TUNING EXECUTION\n",
        "# Training the model with optimized hyperparameters\n",
        "# ============================================================================\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Training configuration optimized for Turkish e-commerce\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        # Batch size and gradient settings\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=8,  # Effective batch size = 16\n",
        "\n",
        "        # Learning rate and scheduling\n",
        "        learning_rate=2e-4,\n",
        "        warmup_steps=20,\n",
        "        num_train_epochs=3,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "\n",
        "        # Optimization settings\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        label_smoothing_factor=0.1,\n",
        "\n",
        "        # Precision settings\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "\n",
        "        # Logging and saving\n",
        "        logging_steps=10,\n",
        "        output_dir=\"./turkish-ecommerce-model\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "\n",
        "        # Memory optimization\n",
        "        dataloader_pin_memory=False,\n",
        "        remove_unused_columns=False,\n",
        "\n",
        "        # Disable external logging\n",
        "        report_to=\"none\",\n",
        "        seed=42,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(\"üîß Trainer configured successfully!\")\n",
        "print(\"\\nüöÄ Starting fine-tuning process...\")\n",
        "print(\"‚è±Ô∏è  This may take 15-30 minutes depending on your GPU...\")\n",
        "\n",
        "# Start training\n",
        "trainer_stats = trainer.train()\n",
        "\n",
        "print(\"\\n‚úÖ Fine-tuning completed!\")\n",
        "print(\"üìä Training Statistics:\")\n",
        "print(f\"   Final Loss: {trainer_stats.training_loss:.4f}\")\n",
        "print(f\"   Training Steps: {trainer_stats.global_step}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model_save_path = \"./turkish-ecommerce-final\"\n",
        "trainer.save_model(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "print(f\"\\nüíæ Model saved to: {model_save_path}\")"
      ],
      "metadata": {
        "id": "ZASEb9z-1umr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üß™ MODEL TESTING & VALIDATION\n",
        "# Evaluating the fine-tuned model performance\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Prepare model for inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "def extract_turkish_ecommerce(html_content: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extract product information from Turkish e-commerce HTML.\n",
        "\n",
        "    Args:\n",
        "        html_content (str): Raw HTML content\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Extracted product information or error details\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"### G√∂rev:\n",
        "A≈üaƒüƒ±daki T√ºrk√ße e-ticaret √ºr√ºn sayfasƒ±ndan bilgileri √ßƒ±kar:\n",
        "\n",
        "{html_content}\n",
        "\n",
        "### √áƒ±ktƒ±:\n",
        "\"\"\"\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.3,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract JSON from response\n",
        "    try:\n",
        "        json_start = response.find('### √áƒ±ktƒ±:')\n",
        "        if json_start == -1:\n",
        "            return {\"error\": \"Output header not found\", \"raw_response\": response}\n",
        "\n",
        "        json_start += len('### √áƒ±ktƒ±:')\n",
        "        json_str = response[json_start:].strip()\n",
        "\n",
        "        # Clean up response\n",
        "        if '<|endoftext|>' in json_str:\n",
        "            json_str = json_str.split('<|endoftext|>')[0].strip()\n",
        "\n",
        "        # Parse JSON\n",
        "        result = json.loads(json_str)\n",
        "        return result\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        return {\n",
        "            \"error\": f\"JSON parsing error: {str(e)}\",\n",
        "            \"raw_response\": response,\n",
        "            \"extracted_json\": json_str if 'json_str' in locals() else \"Not found\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"General error: {str(e)}\", \"raw_response\": response}\n",
        "\n",
        "# Test cases\n",
        "test_cases = [\n",
        "    {\n",
        "        \"name\": \"iPhone Test\",\n",
        "        \"html\": \"\"\"\n",
        "<div class=\"product-page\">\n",
        "    <h1>Apple iPhone 15 Pro 128GB - Doƒüal Titanyum</h1>\n",
        "    <div class=\"price-section\">\n",
        "        <span class=\"price\">54.999 TL</span>\n",
        "        <span class=\"old-price\">59.999 TL</span>\n",
        "        <span class=\"discount\">%8 ƒ∞ndirim</span>\n",
        "    </div>\n",
        "    <div class=\"brand\">Apple</div>\n",
        "    <div class=\"category\">Akƒ±llƒ± Telefon</div>\n",
        "    <div class=\"seller\">Apple Store</div>\n",
        "    <div class=\"rating\">4.8 ‚≠ê (2.156 deƒüerlendirme)</div>\n",
        "    <div class=\"features\">\n",
        "        <li>128GB Depolama</li>\n",
        "        <li>Titanium Tasarƒ±m</li>\n",
        "        <li>48MP Ana Kamera</li>\n",
        "    </div>\n",
        "    <div class=\"shipping\">√úcretsiz Kargo</div>\n",
        "    <div class=\"stock\">Stokta var</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Samsung Test\",\n",
        "        \"html\": \"\"\"\n",
        "<div class=\"urun-detay\">\n",
        "    <h1>Samsung Galaxy S24 Ultra 256GB - Siyah</h1>\n",
        "    <div class=\"fiyat\">\n",
        "        <span class=\"guncel-fiyat\">45.999 TL</span>\n",
        "        <span class=\"eski-fiyat\">49.999 TL</span>\n",
        "        <span class=\"indirim\">%8 ƒ∞ndirim</span>\n",
        "    </div>\n",
        "    <div class=\"marka\">Samsung</div>\n",
        "    <div class=\"kategori\">Telefon</div>\n",
        "    <div class=\"satici\">Samsung T√ºrkiye</div>\n",
        "    <div class=\"puan\">4.6 (1.234 deƒüerlendirme)</div>\n",
        "    <ul class=\"ozellikler\">\n",
        "        <li>256GB Dahili Hafƒ±za</li>\n",
        "        <li>12GB RAM</li>\n",
        "        <li>200MP Ana Kamera</li>\n",
        "    </ul>\n",
        "    <div class=\"kargo\">√úcretsiz Kargo</div>\n",
        "    <div class=\"stok\">Stokta mevcut</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Run tests\n",
        "print(\"üß™ Running model validation tests...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "successful_tests = 0\n",
        "total_tests = len(test_cases)\n",
        "\n",
        "for i, test_case in enumerate(test_cases, 1):\n",
        "    print(f\"\\nüìã Test {i}: {test_case['name']}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    result = extract_turkish_ecommerce(test_case['html'])\n",
        "\n",
        "    if \"error\" not in result:\n",
        "        print(\"‚úÖ Success!\")\n",
        "        print(json.dumps(result, ensure_ascii=False, indent=2))\n",
        "        successful_tests += 1\n",
        "    else:\n",
        "        print(\"‚ùå Error occurred:\")\n",
        "        print(f\"Error: {result['error']}\")\n",
        "\n",
        "print(f\"\\nüìä Test Results: {successful_tests}/{total_tests} tests passed\")\n",
        "print(f\"Success Rate: {(successful_tests/total_tests)*100:.1f}%\")"
      ],
      "metadata": {
        "id": "XMnaKPjP1wNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üîß GGUF CONVERSION FOR OLLAMA DEPLOYMENT\n",
        "# Converting fine-tuned model to efficient GGUF format\n",
        "# ============================================================================\n",
        "\n",
        "print(\"üîÑ Converting model to GGUF format for Ollama deployment...\")\n",
        "print(\"‚è±Ô∏è  This process may take several minutes...\")\n",
        "\n",
        "# Convert to GGUF with Q4_K_M quantization (optimal size/quality balance)\n",
        "model.save_pretrained_gguf(\n",
        "    \"turkish_ecommerce_gguf\",\n",
        "    tokenizer,\n",
        "    quantization_method=\"q4_k_m\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ GGUF conversion completed!\")\n",
        "\n",
        "# Display file information\n",
        "import os\n",
        "gguf_path = \"turkish_ecommerce_gguf\"\n",
        "if os.path.exists(gguf_path):\n",
        "    print(f\"\\nüìÅ GGUF files generated in: {gguf_path}/\")\n",
        "    for file in os.listdir(gguf_path):\n",
        "        if file.endswith('.gguf'):\n",
        "            file_path = os.path.join(gguf_path, file)\n",
        "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "            print(f\"   üìÑ {file}: {size_mb:.1f} MB\")\n",
        "\n",
        "print(\"\\nüéØ Next Steps:\")\n",
        "print(\"1. Download the GGUF files to your local machine\")\n",
        "print(\"2. Install Ollama (https://ollama.ai)\")\n",
        "print(\"3. Create and run the model locally\")"
      ],
      "metadata": {
        "id": "IKf2q0-v1yJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# üì• DOWNLOAD GGUF FILES TO LOCAL MACHINE\n",
        "# Using Google Drive for large file transfer\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "print(\"‚òÅÔ∏è  Uploading GGUF files to Google Drive...\")\n",
        "\n",
        "try:\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive connected!\")\n",
        "\n",
        "    # Create destination directory\n",
        "    drive_destination = \"/content/drive/MyDrive/turkish_ecommerce_gguf\"\n",
        "\n",
        "    if os.path.exists(\"turkish_ecommerce_gguf\"):\n",
        "        # Copy files to Google Drive\n",
        "        if os.path.exists(drive_destination):\n",
        "            shutil.rmtree(drive_destination)\n",
        "\n",
        "        shutil.copytree(\"turkish_ecommerce_gguf\", drive_destination)\n",
        "        print(f\"‚úÖ Files uploaded to Google Drive: {drive_destination}\")\n",
        "\n",
        "        # Verify upload\n",
        "        uploaded_files = os.listdir(drive_destination)\n",
        "        total_size = 0\n",
        "        for file in uploaded_files:\n",
        "            file_path = os.path.join(drive_destination, file)\n",
        "            if os.path.isfile(file_path):\n",
        "                size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "                total_size += size_mb\n",
        "                print(f\"   üìÑ {file}: {size_mb:.1f} MB\")\n",
        "\n",
        "        print(f\"\\nüìä Total size: {total_size:.1f} MB\")\n",
        "        print(\"\\nüì± Access your files:\")\n",
        "        print(\"1. Open Google Drive: https://drive.google.com\")\n",
        "        print(\"2. Navigate to 'turkish_ecommerce_gguf' folder\")\n",
        "        print(\"3. Download the .gguf file to your computer\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå GGUF folder not found!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error uploading to Google Drive: {e}\")\n",
        "    print(\"üí° Try downloading files manually using Google Colab's file browser\")"
      ],
      "metadata": {
        "id": "VW5fqCaw10ah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}